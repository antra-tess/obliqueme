# Model configurations for the Discord bot
models:
  # Base models (use completions API)
  llama_405b_base:
    name: "Llama 3.1 405B (Base)"
    model_id: "meta-llama/Meta-Llama-3.1-405B"
    type: "base"
    endpoint: "https://api.hyperbolic.xyz/v1/completions"
    max_tokens: 200
    quantization: ""
    supports_n_parameter: false

  llama_405b_base_or:
    name: "Llama 3.1 405B (Base) OpenRouter"
    model_id: "meta-llama/llama-3.1-405b"
    type: "base"
    endpoint: "https://api.hyperbolic.xyz/v1/completions"
    max_tokens: 200
    quantization: ""
    supports_n_parameter: false

  # Instruct models (use chat API with prefill)
  claude_opus:
    name: "Claude 3 Opus"
    model_id: "anthropic/claude-3-opus"
    type: "instruct"
    endpoint: "https://openrouter.ai/api/v1/chat/completions"
    max_tokens: 600
    quantization: ""
    system_prompt: "The assistant is in CLI simulation mode, and responds to the user's CLI commands only with outputs of the commands."
    user_prefix: "<cmd>cat untitled.log</cmd>"
    supports_n_parameter: true
    
  claude_opus_4:
    name: "Claude 4 Opus"
    model_id: "anthropic/claude-opus-4"
    type: "instruct"
    endpoint: "https://openrouter.ai/api/v1/chat/completions"
    max_tokens: 600
    quantization: ""
    system_prompt: "The assistant is in CLI simulation mode, and responds to the user's CLI commands only with outputs of the commands."
    user_prefix: "<cmd>cat untitled.log</cmd>"
    supports_n_parameter: true
    
  claude_sonnet:
    name: "Claude 3.5 Sonnet"
    model_id: "anthropic/claude-3.5-sonnet"
    type: "instruct"
    endpoint: "https://openrouter.ai/api/v1/chat/completions"
    max_tokens: 600
    quantization: ""
    system_prompt: "The assistant is in CLI simulation mode, and responds to the user's CLI commands only with outputs of the commands."
    user_prefix: "<cmd>cat untitled.log</cmd>"

  claude_sonnet:
    name: "Claude 4 Sonnet"
    model_id: "anthropic/claude-sonnet-4"
    type: "instruct"
    endpoint: "https://openrouter.ai/api/v1/chat/completions"
    max_tokens: 600
    quantization: ""
    system_prompt: "The assistant is in CLI simulation mode, and responds to the user's CLI commands only with outputs of the commands."
    user_prefix: "<cmd>cat untitled.log</cmd>"
    supports_n_parameter: true


# Default model (fallback if none selected)
default_model: "claude-3-opus"

# Bot settings
bot:
  keyword: "obliqueme"
  random_string_length: 10
  message_history_limit: 80 